<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <link rel="stylesheet" href="css/estilos.css">
    <link rel="stylesheet" href="css/prism.css">
    <link rel="stylesheet" href="css/all.css">
    <link  rel="icon"   href="img/favicon.png" type="image/png" />
    <title>Spark</title>
</head>
<body>

<div class="container-head">
    <div class="logos">
        <a href="index.html" class="logo"><img src="img/logo-ute.png" alt="logo" width="90px" height="90px" ></a>
    </div> 
</div>

      

<header>
    <div class="container-menu logo-nav-contenedor">
        <span class="menu-icon"><i class="fas fa-bars"></i></span>
        <nav class="navegacion">
            <ul class="show">
                <strong><li><a href="index.html">Inicio</a></li></strong>
                <strong><li><a href="Presentaciones.html">Presentaciones</a></li></strong>
                <strong><li><a href="Videos.html">Videos</a></li></strong>
               
            </ul>
        </nav>
      </div>
</header>

<div class="container-general">
    <main>
    <div class="container-cuerpo">
    <div class="columna_izquierda">
        <div class="contenido_1">
        
            <strong><h3>Parcial Uno</h3></strong>
        </div>
        <div class="contenido_2">
            <nav class="navegacion_2">
                <ul class="show_2">
                    <li><a href="Expresiones_Lambda.html"><i class="fas fa-sign-in-alt"></i>Expresiones Lambda</a></li> 
                    <li><a href="Hilo_Sincronizacion.html"><i class="fas fa-sign-in-alt"></i>Hilos y Sincronización</a></li>
                    <li><a href="Metodos_estaticos.html"><i class="fas fa-sign-in-alt"></i>Métodos Estáticos</a></li>
                    <li><a href="ForkJoin.html"><i class="fas fa-sign-in-alt"></i>ForkJoin</a></li>
                    <li><a href="JavaStreams.html"><i class="fas fa-sign-in-alt"></i>Java Streams</a></li>
                    <li><a href="ip.html"><i class="fas fa-sign-in-alt"></i>TCP/IP, Sockets UDP</a></li>
                    <li><a href="MapReduce.html"><i class="fas fa-sign-in-alt"></i>MapReduce</a></li>
                    <li><a href="TCP.html"><i class="fas fa-sign-in-alt"></i>Sockets TCP</a></li>
                    <li><a href="Contenedores.html"><i class="fas fa-sign-in-alt"></i>Contenedores</a></li>
                    <li><a href="MaquinaVirtual.html"><i class="fas fa-sign-in-alt"></i>Maquina virtual</a></li>
                    <li><a href="VirtualBox.html"><i class="fas fa-sign-in-alt"></i>Virtual Box</a></li>
                    <li><a href="Docker.html"><i class="fas fa-sign-in-alt"></i>Docker</a></li>
                        <!--INICIO SEGUNDO PARCIAL-->
                    <div class="contenido_1"><strong><h3>Parcial Dos</h3></strong></div>
                    <li><a href="Spring.html"><i class="fas fa-sign-in-alt"></i>Spring</a></li>
                    <li><a href="Spring_Boot.html"><i class="fas fa-sign-in-alt"></i>Spring Boot</a></li>
                    <li><a href="inversiondecontrol.html"><i class="fas fa-sign-in-alt"></i>Inversion de control</a></li>
                    <li><a href="InyeccionDependencia.html"><i class="fas fa-sign-in-alt"></i>Inyeccion de Dependencias</a></li>
                    <li><a href="ConvencionSobreConfiguracion.html"><i class="fas fa-sign-in-alt"></i>Convención Sobre Configuración</a></li>
                    <li><a href="SpringMVC.html"><i class="fas fa-sign-in-alt"></i>Creación de aplicaciones web con Spring MVC</a></li>
                    <li><a href="Orm.html"><i class="fas fa-sign-in-alt"></i>ORM</a></li>
                    <li><a href="JPA.html"><i class="fas fa-sign-in-alt"></i>JPA</a></li>
                    <li><a href="JSP.html"><i class="fas fa-sign-in-alt"></i>JSP</a></li>
                    <li><a href="Thymeleaf.html"><i class="fas fa-sign-in-alt"></i>Thymeleaf</a></li>
                    <li><a href="FreeMarker.html"><i class="fas fa-sign-in-alt"></i>FreeMarker</a></li>    
                    <li><a href="Groovy.html"><i class="fas fa-sign-in-alt"></i>Groovy</a></li>
                    <li><a href="ServicioWeb.html"><i class="fas fa-sign-in-alt"></i>Servicio Web</a></li>
                    <div class="contenido_1"><strong><h3>Parcial Tres</h3></strong> </div>   
                           <!--INICIO TERCER PARCIAL-->
                    <li><a href="NFS.html"><i class="fas fa-sign-in-alt"></i>NFS</a></li>
                    <li><a href="samba.html"><i class="fas fa-sign-in-alt"></i>Samba</a></li>
                     <!--Falta subir-->
                     <li><a href="GlusterFs.html"><i class="fas fa-sign-in-alt"></i>GlusterFS</a></li>
                    <!---->
                    <li><a href="HDFS.html"><i class="fas fa-sign-in-alt"></i>HDFS</a></li>
                     <!--Falta subir-->
                    <li><a href="Hadoop.html"><i class="fas fa-sign-in-alt"></i>Hadoop</a></li>
                    <li><a href="Spark.html"><i class="fas fa-sign-in-alt"></i>Spark</a></li>
                    <li><a href="MultiProceso.html"><i class="fas fa-sign-in-alt"></i>Multiproceso</a></li>
                     <!---->
                    <li><a href="mpi.html"><i class="fas fa-sign-in-alt"></i>MPI</a></li>
                     <!--Falta subir-->
                    <li><a href="ZeroMQ.html"><i class="fas fa-sign-in-alt"></i>ZeroMQ</a></li>
                    <li><a href="NNG.html"><i class="fas fa-sign-in-alt"></i>NNG</a></li>
                  
                    <!---->
                    <li><a href="CPU.html"><i class="fas fa-sign-in-alt"></i>CPU</a></li>
                    <li><a href="DPC.html"><i class="fas fa-sign-in-alt"></i>DPC++</a></li>
                    <li><a href="fpga.html"><i class="fas fa-sign-in-alt"></i>FPGA</a></li>
			<li><a href="GPU.html"><i class="fas fa-sign-in-alt"></i>GPU</a></li>
                <li><a href="MPJ.html"><i class="fas fa-sign-in-alt"></i>MPJ</a></li>
            </ul>
            </nav>
        </div>
    </div>
    
    
    <section class="columna_derecha">
        <div text align="center"><h2>Spark</h2></div>
        <P><STRong> Que es Spark  </STRong></P>
    

            <p>  Spark es un framework de computación en clúster open-source.
            </p>
            
            <p>Fue desarrollada originariamente en la Universidad de California, en el AMPLab de Berkeley. 
            </p>
            <p>El código base del proyecto Spark fue donado más tarde a la 
                Apache Software Foundation que se encarga de su mantenimiento desde entonces.
            </p>
            <P> Spark proporciona una interfaz para la programación de clusters completos con Paralelismo de Datos implícito y tolerancia a fallos.
                            </p>
           
           
        <div text align="center"><img src="img/logo.png" height="300" width="300"></div>

      
        <P><STRong> Historia  </STRong></P>
        
    
           <p>Spark fue desarrollado en sus inicios por Matei Zaharia en el AMPLab de la UC Berkeley en 2009. 
               Fue liberado como código abierto en 2010 bajo licencia BSD. </p>
           <p>En 2013, el proyecto fue donado a la Apache Software Foundation y se modificó su licencia a Apache 2.0. 
               En febrero de 2014, Spark se convirtió en un Top-Level Apache Project. </p> 
           <p> En noviembre de 2014, la empresa de su fundador, M. Zaharia, 
               Databricks obtuvo un nuevo récord mundial en la ordenación a gran escala usando Spark </p>
           <p> Hacia 2015, Spark tenía más de 1000 contribuidores convirtiéndose en uno de los proyectos más activos de la Apache Software Foundation
               y en uno de los proyectos de big data open source más activos. </p>
           <p>Dada la popularidad de la plataforma hacia el 2014, programas de pago como la General Assembly and free fellowships like 
               The Data Incubator comenzaron a ofrecer cursos de formación personalizados  </p>
                
                
           
        <div text align="center"><img src="img/sparki.png" height="350" width="350"></div>
        <P><STRong> Introducción </STRong></P>
        
        <p> Apache Spark tiene la base de su arquitectura en el llamado RDD o Resilient Distributed DataSet que es un multiset de solo lectura de ítems de 
            datos distribuidos a lo largo de un clúster de máquinas que se mantiene en un entorno tolerante de fallos.
        </p>
        <p>En Spark 1.x, RDD era la API principal pero con el desarrollo de Spark 2.0, se recomienda la utilización de la API DataSet.
            Aunque la API RDD no se considera descatalogada.10​11​ la tecnología RDD todavía está presente en la base de la API DataSet.
        </p>   
         <p>Spark y sus RDDs fueron desarrollados en 2012 en respuesta a las limitaciones del paradigma de computación en clúster MapReduce que fuerza a la utilización de una estructura lineal dataflow en particular en los programas distribuidos:
              Los programas basados en MapReduce leen los datos de entrada desde disco, que mapea una función a lo largo de los datos, reduce los resultados del mapa y almacena los resultados de la reducción en disco </p>
        <p>Los RDDs de Spark funcionan como un working set para los programas distribuidos que ofrecen una forma (deliberadamente) 
            restringida de la memoria compartida distribuida.
            Spark facilita la implementación de tanto algoritmos iterativos que visitan su dataset muchas veces en un mismo bucle 
            tanto como el análisis de datos interactivo/exploratorio (i.e.    
    a loop, and interactive/exploratory data analysis, i.e., the repeated database-style querying of data.</p>   
         <p>La latencia de estas aplicaciones se puede reducir en varios órdenes de magnitud en comparación 
             con la implementación basada en MapReduce (comúnmente utilizada i.e. en los stacks basados en Apache Hadoop.</p>
 
         <p>Más allá de los algoritmos de tipor iterativos, están los algoritmos de entrenamiento 
             para sistemas de machine learning , que constituyeron el impulso inicial del desarrollo de Apache Spark.</p>

                     <p> Apache Spark requiere de un cluster manager y un sistema de almacenamiento distribuido.</p>
<p></p>
        <strong><p> Para la gestión del clúster, Spark soporta las opciones siguientes:</p></strong>
            
           <p>-Spark Standalone (Cluster Spark Nativo).</p> 
            <p>-Hadoop YARN.</p> 
            <p>-Apache Mesos.  </p>     
        <p> </p>

        <strong><p> Para el almacenamiento distribuido, Spark presenta interfaces hacia una gran variedad de plataformas:</p></strong>

        <p>-Hadoop Distributed File System (HDFS)17​.</p>
        <p>-MapR File System (MapR-FS)18​.</p>
        <p>- Cassandra19​.</p>
        <p>- OpenStack Swift.</p>
        <p>-   Amazon S3.</p>
        <p>- Azure Databricks.</p>
        <p>-Kudu.</p>
        <p>I-ncluso soporta una solución personalizada.</p>
        
        <p> Spark también soporta un modo local pseudo-distribuido, normalmente utilizado solamente para pruebas o en entornos de desarrollo donde el almacenamiento distribuido no es obligatorio y se puede usar el sistema de archivos local; en un escenarion como este, 
            Spark se ejecuta en una única máquina con un executor por cada core de CPU.</p>
            <div text align="center"><img src="img/imag.png" height="350" width="350"></div>

            <P><STRong> <li>Apache Spark: Su relación con Hadoop</li></STRong></P>

            <p>Una de las grandes preguntas sobre Spark es su relación con Hadoop. ¿Se trata de otra tecnología competencia del famoso framework? En realidad, Spark es la evolución natural de Hadoop, cuya funcionalidad es muy rígida y limitada en el 
                sentido de que no aprovecha al máximo las capacidades del procesamiento distribuido.
            </p>
             <p>Algunas de las evoluciones que supone Spark frente a su predecesor son el procesamiento en memoria que disminuye las operaciones de 
                 lectura/escritura, la posibilidad de análisis interactivo con SQL  (similar a Hive en cierto modo) y la facilidad para interactuar con 
                 múltiples sistemas de almacenamiento persistente.</p>
             <p> </p>

        
       <strong><p><li>   Apache Spark: ¿Cómo funciona?</li></p></strong> 
       <p>Apache Spark es un motor de procesamiento distribuido responsable de orquestar, distribuir y monitorizar aplicaciones que constan 
        de múltiples tareas de procesamiento de datos sobre varias máquinas de trabajo, que forman un cluster.</p>
    <p> Como ya hemos mencionado, es posible leer los datos desde diferentes soluciones de almacenamiento persistente como Amazon S3 o Google Storage,  sistemas de almacenamiento 
        distribuido como HDFS, sistemas key-value como Apache Cassandra, o buses de mensajes como Kafka. </p>
    <p>A pesar de ello, Spark no almacena datos en sí mismo, sino que tiene el foco puesto en el procesamiento. Este es uno de los puntos que lo diferencian de Hadoop, que incluye tanto un almacenamiento 
        persistente (HDFS) como un sistema de procesamiento (MapReduce) de un manera muy integrada.  </p>
    <p>Es importante hablar de la velocidad de procesamiento: la clave es la posibilidad que ofrece Spark para realizar el procesamiento en memoria. Esto, y la extensión del popular MapReduce para permitir de manera eficiente otros tipos de operaciones: 
        Queries interactivas y Procesamiento en Streaming.</p>


        <strong><p><li>  Apache Spark: ¿Cuáles son sus funciones?</li></p></strong> 
        <p> Respecto a su propósito general, la virtud de Spark es estar diseñado para cubrir una amplia 
            gama de cargas de trabajo que previamente requerían sistemas distribuidos diferentes.</p> 
             <p>   Éstos sistemas incluyen procesamiento batch, algoritmos iterativos, queries interactivas, procesamiento streaming… a
                  menudo empleados todos ellos en un pipeline típico de análisis de datos. </P>
                <p> Por último, hemos dicho que Spark es flexible en su utilización, y es que ofrece una serie de APIs que permiten a usuarios con diferentes backgrounds poder utilizarlo. Incluye APIs de Python, Java, Scala, SQL y R, 
                    con funciones integradas y en general una performance razonablemente buena en todas ellas.</P>
 
            <div text align="center"><img src="img/sk.jpg"" height="350" width="350"></div>
            <p>
            </p>
            
      </section>
    

<div class="container_busqueda">
   
    <div id="search-wrapper">
        <input type="search" id="search" placeholder="Buscar"/>
        <i class="fa fa-search"></i>
      </div>
    <ul id="resultado" class="lista_busqueda">
        
    </ul>
</div>
</div>
</div>
</main>


<footer>
    <div class="container-pie">
        <div class="copyright">
           <p>&copy; 2020 Página realizada por estudiantes de la Universidad UTE.</p> 
        </div>
    </div>
</footer>
</div>

<script src="js/jQuery.js"></script>
<script src="js/scripts.js"></script>



<script>
    const temas = [  /*Cargar aqui enlaces para la busqueda con el mismo formato.*/
    {titulo: '<a href="Expresiones_Lambda.html">Expresiones Lambda</a>'},   
        {titulo: '<a href="Metodos_estaticos.html">Métodos Estáticos</a>'},   
        {titulo: '<a href="ForkJoin.html">ForkJoin</a>'}, 
        {titulo: '<a href="Hilo_Sincronizacion.html">Hilos y Sincronización</a>'},
        {titulo: '<a href="JavaStreams.html">Java Streams</a>'},    
        {titulo: '<a href="ip.html">TCP/IP, Sockets UDP</a>'}, 
        {titulo: '<a href="MapReduce.html">MapReduce</a>'}, 
        {titulo: '<a href="TCP.html">Sockets UTP</a>'}, 
        {titulo: '<a href="Contenedores.html">Contenedores</a>'}, 
		{titulo: '<a href="VirtualBox.html">VirtualBox</a>'}, 
        {titulo: '<a href="Docker.html">Docker</a>'}, 
        {titulo: '<a href="MaquinaVirtual.html">Máquina Virtual </a>'}, 
        {titulo: '<a href="InyeccionDependencia.html">Inyeccion de Dependencias </a>'}, 
        {titulo: '<a href="ConvencionSobreConfiguracion.html">Convención Sobre Configuración </a>'}, 
        {titulo: '<a href="FreeMarker.html">FreeMarker </a>'}, 
        {titulo: '<a href="SpringMVC.html">Creación de aplicaciones web con Spring MVC </a>'},
        {titulo: '<a href="Groovy.html">Groovy </a>'},
        {titulo: '<a href="Spring.html">Spring </a>'},
        {titulo: '<a href="Spring_Boot.html">Spring boot </a>'},
        {titulo: '<a href="Orm.html">ORM </a>'},
        {titulo: '<a href="JPA.html">JPA </a>'},  
        {titulo: '<a href="JSP.html">JSP </a>'},
        {titulo: '<a href="inversiondecontrol.html">Inversion de Control </a>'}, 
        {titulo: '<a href="ServicioWeb.html">Servicio Web </a>'},

        {titulo: '<a href="NFS.html">NFS</a>'},
        {titulo: '<a href="samba.html">Samba</a>'},
        {titulo: '<a href="GlusterFs.html">GlusterFs</a>'},
        {titulo: '<a href="HDFS.html">HDFS </a>'},
        {titulo: '<a href="Hadoop.html">Hadoop</a>'},
        {titulo: '<a href="Spark.html">Spark </a>'},
        {titulo: '<a href="MultiProceso.html">Multiproceso </a>'},
        {titulo: '<a href="mpi.html">Mpi</a>'},
        {titulo: '<a href="ZeroMQ.html">ZeroMQ </a>'},
        {titulo: '<a href="NNG.html">NNG </a>'},
        {titulo: '<a href="CPU.html">CPU </a>'},
        {titulo: '<a href="DPC.html">DPC++ </a>'},
        {titulo: '<a href="fpga.html">FPGA</a>'}, 
		    {titulo: '<a href="GPU.html">GPU </a>'},
        {titulo: '<a href="MPJ.html">MPJ </a>'},
    ]
    const formulario= document.querySelector('#search');
    const boton= document.querySelector('#boton');
    const resultado=document.querySelector('#resultado');

    const filtrar = ()=>{
       resultado.innerHTML='';

       const texto = formulario.value.toLowerCase();
       for(let tema of temas ){
           let titulo=tema.titulo.toLowerCase();
           if(titulo.indexOf(texto) !== -1){
               
                resultado.innerHTML += '<li>'+tema.titulo+'</li>'
         }
        }
        if(resultado.innerHTML===''){
            resultado.innerHTML += '<li>Enlace no Encontrado...</li>'
        }
    }
    //boton.addEventListener('click',filtrar)
    formulario.addEventListener('keyup',filtrar);
   
    
</script>
</body>
</html>
