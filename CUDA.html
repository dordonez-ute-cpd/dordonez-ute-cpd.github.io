<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <link rel="stylesheet" href="css/estilos.css">
    <link rel="stylesheet" href="css/prism.css">
    <link rel="stylesheet" href="css/all.css">
    <link  rel="icon"   href="img/favicon.png" type="image/png" />
    <title>CUDA</title>
</head>

<div class="container-head">
    <div class="logos">
        <a href="index.html" class="logo"><img src="img/logo-utet.png" alt="logo" width="100px" height="84px" ></a>
    </div> 
</div>

      


<body>
    <header>
        <div class="container-menu logo-nav-contenedor">
            <span class="menu-icon"><i class="fas fa-bars"></i></span>
            <nav class="navegacion">
                <ul class="show">
                    <strong><li><a href="index.html">Inicio</a></li></strong>
                    <strong><li><a href="Presentaciones.html">Presentaciones</a></li></strong>
                    <strong><li><a href="Videos.html">Videos</a></li></strong>
                   
                </ul>
            </nav>
          </div>
    </header>

    <div class="container-general">
        <main>
        <div class="container-cuerpo">
        <div class="columna_izquierda">
            <div class="contenido_1">
                <strong><h3>Parcial Uno</h3></strong>
            </div>
            <div class="contenido_2">
                <nav class="navegacion_2">
                    <ul class="show_2">
                        <li><a href="Expresiones_Lambda.html"><i class="fas fa-sign-in-alt"></i>Expresiones Lambda</a></li> 
                        <li><a href="Hilo_Sincronizacion.html"><i class="fas fa-sign-in-alt"></i>Hilos y Sincronización</a></li>
                        <li><a href="Metodos_estaticos.html"><i class="fas fa-sign-in-alt"></i>Métodos Estáticos</a></li>
                        <li><a href="ForkJoin.html"><i class="fas fa-sign-in-alt"></i>ForkJoin</a></li>
                        <li><a href="JavaStreams.html"><i class="fas fa-sign-in-alt"></i>Java Streams</a></li>
                        <li><a href="ip.html"><i class="fas fa-sign-in-alt"></i>TCP/IP, Sockets UDP</a></li>
                        <li><a href="MapReduce.html"><i class="fas fa-sign-in-alt"></i>MapReduce</a></li>
                        <li><a href="TCP.html"><i class="fas fa-sign-in-alt"></i>Sockets TCP</a></li>
                        <li><a href="Contenedores.html"><i class="fas fa-sign-in-alt"></i>Contenedores</a></li>
                        <li><a href="MaquinaVirtual.html"><i class="fas fa-sign-in-alt"></i>Maquina virtual</a></li>
                        <li><a href="VirtualBox.html"><i class="fas fa-sign-in-alt"></i>Virtual Box</a></li>
                        <li><a href="Docker.html"><i class="fas fa-sign-in-alt"></i>Docker</a></li>
                            <!--INICIO SEGUNDO PARCIAL-->
                        <div class="contenido_1"><strong><h3>Parcial Dos</h3></strong></div>
                        <li><a href="Spring.html"><i class="fas fa-sign-in-alt"></i>Spring</a></li>
                        <li><a href="Spring_Boot.html"><i class="fas fa-sign-in-alt"></i>Spring Boot</a></li>
                        <li><a href="inversiondecontrol.html"><i class="fas fa-sign-in-alt"></i>Inversion de control</a></li>
                        <li><a href="InyeccionDependencia.html"><i class="fas fa-sign-in-alt"></i>Inyeccion de Dependencias</a></li>
                        <li><a href="ConvencionSobreConfiguracion.html"><i class="fas fa-sign-in-alt"></i>Convención Sobre Configuración</a></li>
                        <li><a href="SpringMVC.html"><i class="fas fa-sign-in-alt"></i>Creación de aplicaciones web con Spring MVC</a></li>
                        <li><a href="Orm.html"><i class="fas fa-sign-in-alt"></i>ORM</a></li>
                        <li><a href="JPA.html"><i class="fas fa-sign-in-alt"></i>JPA</a></li>
                        <li><a href="JSP.html"><i class="fas fa-sign-in-alt"></i>JSP</a></li>
                        <li><a href="Thymeleaf.html"><i class="fas fa-sign-in-alt"></i>Thymeleaf</a></li>
                        <li><a href="FreeMarker.html"><i class="fas fa-sign-in-alt"></i>FreeMarker</a></li>    
                        <li><a href="Groovy.html"><i class="fas fa-sign-in-alt"></i>Groovy</a></li>
                        <li><a href="ServicioWeb.html"><i class="fas fa-sign-in-alt"></i>Servicio Web</a></li>
                        <div class="contenido_1"><strong><h3>Parcial Tres</h3></strong> </div>   
                                         <!--INICIO TERCER PARCIAL-->
                <li><a href="NFS.html"><i class="fas fa-sign-in-alt"></i>NFS</a></li>
                <li><a href="samba.html"><i class="fas fa-sign-in-alt"></i>Samba</a></li>
                 <!--Falta subir-->
                 <li><a href="GlusterFs.html"><i class="fas fa-sign-in-alt"></i>GlusterFS</a></li>
                <!---->
                <li><a href="HDFS.html"><i class="fas fa-sign-in-alt"></i>HDFS</a></li>
                 <!--Falta subir-->
                <li><a href="Hadoop.html"><i class="fas fa-sign-in-alt"></i>Hadoop</a></li>
                <li><a href="Spark.html"><i class="fas fa-sign-in-alt"></i>Spark</a></li>
                <li><a href="MultiProceso.html"><i class="fas fa-sign-in-alt"></i>Multiproceso</a></li>
                 <!---->
                <li><a href="mpi.html"><i class="fas fa-sign-in-alt"></i>MPI</a></li>
                 <!--Falta subir-->
                <li><a href="ZeroMQ.html"><i class="fas fa-sign-in-alt"></i>ZeroMQ</a></li>
                <li><a href="NNG.html"><i class="fas fa-sign-in-alt"></i>NNG</a></li>
                <!---->
                <li><a href="DPC.html"><i class="fas fa-sign-in-alt"></i>DPC++</a></li>
                <li><a href="fpga.html"><i class="fas fa-sign-in-alt"></i>FPGA</a></li>

		        <li><a href="CPU.html"><i class="fas fa-sign-in-alt"></i>CPU</a></li>
                <li><a href="CUDA.html"><i class="fas fa-sign-in-alt"></i>CUDA</a></li>

                </ul>
                </nav>
            </div>
        </div>
        
        <section class="columna_derecha">
            <div text align="center"><h2>CUDA</h2></div>
        
            <p>
                
CUDA es una plataforma de computación paralela y un modelo de programación desarrollado por Nvidia para computación general en sus propias GPU (unidades de procesamiento de gráficos). CUDA permite a los desarrolladores acelerar las aplicaciones de computación intensiva al aprovechar la potencia de las GPU para la parte paralelizable de la computación.

                
            </p>
            <p>
                Si bien se han propuesto otras API para GPU, como OpenCL, y hay GPU competitivas de otras empresas, como AMD, la combinación de GPU CUDA y Nvidia domina varias áreas de aplicación, incluido el aprendizaje profundo, y es la base para algunas de las las computadoras más rápidas del mundo.

            </p>
           <br>
           
           <div align="center"><img srcset="img/cuda1.jpg 320w,
            img/cuda1.jpg 480w,img/cuda1.jpg 800w"
            sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
            src="img/cuda1.jpg"  alt="Proceso" class="imagen">
        </div>
        
  
     <h2>El origen de CUDA</h2>
            
        <br>
            <p>En 2003, un equipo de investigadores dirigido por Ian Buck dio a conocer Brook, el primer modelo de programación ampliamente adoptado para extender C con construcciones paralelas de datos. Más tarde, Buck se unió a Nvidia y lideró el lanzamiento de CUDA en 2006, la primera solución comercial para computación de propósito general en GPU.</p>
           
        <h2>OPENCL VS CUDA</h2>
         
            <p>       
                El competidor de CUDA OpenCL fue lanzado por Apple y el Grupo Khronos en 2009, en un intento de proporcionar un estándar para la computación heterogénea que no se limitara a las CPU Intel / AMD con GPU Nvidia. Si bien OpenCL suena atractivo debido a su generalidad, no ha funcionado tan bien como CUDA en las GPU de Nvidia, y muchos marcos de aprendizaje profundo no lo admiten o lo admiten solo como una ocurrencia tardía una vez que se ha lanzado su compatibilidad con CUDA.
            
            <h2>Aumento del rendimiento de CUDA
            </h2>
        
            <p>
           
CUDA ha mejorado y ampliado su alcance a lo largo de los años, más o menos al mismo ritmo que las GPU Nvidia mejoradas. A partir de la versión 9.2 de CUDA, al utilizar varias GPU de servidor P100, puede realizar mejoras de rendimiento de hasta 50 veces superiores a las de las CPU. El V100 (no mostrado en esta figura) es tres veces más rápido para algunas cargas. La generación anterior de GPU de servidor, la K80, ofrecía mejoras de rendimiento de 5 a 12 veces superiores a las de las CPU.
            </p>
            <p>
    
            <div align="center"><img srcset="img/cuda2.png 320w,
                img/cuda2.png  480w,img/cuda2.png  800w"
                sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
                src="img/cuda2.png"  alt="Proceso" class="imagen">
            </div>
<p>
    El aumento de velocidad de las GPU ha llegado justo a tiempo para la informática de alto rendimiento. El aumento del rendimiento de un solo subproceso de las CPU a lo largo del tiempo, que según la ley de Moore se duplicaría cada 18 meses, se ha ralentizado hasta un 10 por ciento por año a medida que los fabricantes de chips encontraron límites físicos, incluidos límites de tamaño en la resolución de la máscara de chip y el rendimiento del chip durante el proceso de fabricación. y límites de calor en las frecuencias de reloj en tiempo de ejecución.
</p>

<div align="center"><img srcset="img/cuda3.png 320w,
    img/cuda3.png 480w,img/cuda3.png  800w"
    sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
    src="img/cuda3.png"  alt="Proceso" class="imagen">
</div>
            <p>
           
Las GPU CUDA y Nvidia se han adoptado en muchas áreas que necesitan un alto rendimiento informático de punto flotante, como se resume gráficamente en la imagen de arriba. Una lista más completa incluye:

            </p>

            <li>Computación Financiera</li>
            <li>modelado climático</li>
            <li>Data science</li>
            <li>Análisis de datos</li>
            <li>Deep Learning</li>
            <li>Arquitectura, Ingeniería, Construcción</li>
            <li>Medicina</li>
            <li>Entretenmiento</li>
            <li>Herramientos administrativas</li>
            <li>Seguridad</li>




        <h2>CUDA EN DEEP LEARNING</h2>
            <p>
             En deep learning   tiene una enorme necesidad de velocidad informática. Por ejemplo, para entrenar los modelos para Google Translate en 2016, los equipos de Google Brain y Google Translate realizaron cientos de ejecuciones de TensorFlow de una semana usando GPU; habían comprado 2000 GPU de nivel de servidor de Nvidia para este propósito. Sin GPU, esas ejecuciones de entrenamiento hubieran tardado meses en converger en lugar de una semana. Para la implementación de producción de esos modelos de traducción de TensorFlow, Google usó un nuevo chip de procesamiento personalizado, la TPU (unidad de procesamiento de tensor).
            </p>
      
            <p>
                Además de TensorFlow, muchos otros marcos de DL dependen de CUDA para su compatibilidad con GPU, incluidos Caffe2, CNTK, Databricks, H2O.ai, Keras, MXNet, PyTorch, Theano y Torch. En la mayoría de los casos, utilizan la biblioteca cuDNN para los cálculos de redes neuronales profundas. Esa biblioteca es tan importante para el entrenamiento de los marcos de aprendizaje profundo que todos los marcos que utilizan una versión determinada de cuDNN tienen esencialmente los mismos números de rendimiento para casos de uso equivalentes. Cuando CUDA y cuDNN mejoran de una versión a otra, todos los marcos de aprendizaje profundo que se actualizan a la nueva versión ven las ganancias de rendimiento. Donde el rendimiento tiende a diferir de un marco a otro es en qué tan bien se escalan a múltiples GPU y múltiples nodos.
            </p>
            <h2>Programación en CUDA</h2>
            <div align="center"><img srcset="img/cuda4.png 320w,
                img/cuda4.png   480w,img/cuda4.png   800w"
                sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
                src="img/cuda4.png "  alt="Proceso" class="imagen">
            </div>
            <h3>CUDA Toolkit
            </h3>
            <p>

                El kit de herramientas CUDA incluye bibliotecas, herramientas de depuración y optimización, un compilador, documentación y una biblioteca en tiempo de ejecución para implementar sus aplicaciones. Tiene componentes que admiten aprendizaje profundo, álgebra lineal, procesamiento de señales y algoritmos paralelos. En general, las bibliotecas CUDA admiten todas las familias de GPU de Nvidia, pero funcionan mejor en la última generación, como la V100, que puede ser 3 veces más rápida que la P100 para cargas de trabajo de entrenamiento de aprendizaje profundo. El uso de una o más bibliotecas es la forma más sencilla de aprovechar las GPU, siempre que los algoritmos que necesita se hayan implementado en la biblioteca adecuada.
            </p>
        <h3>Librerias de Deep Learning CUDA</h3>

        <p>
            En la esfera del aprendizaje profundo, hay tres bibliotecas principales aceleradas por GPU: cuDNN, que mencioné anteriormente como el componente de GPU para la mayoría de los marcos de aprendizaje profundo de código abierto; TensorRT, que es el tiempo de ejecución y el optimizador de inferencia de aprendizaje profundo de alto rendimiento de Nvidia; y DeepStream, una biblioteca de inferencias de video. TensorRT lo ayuda a optimizar los modelos de redes neuronales, calibrar para obtener una precisión más baja con alta precisión e implementar los modelos entrenados en nubes, centros de datos, sistemas integrados o plataformas de productos automotrices.</p>
            <br>
                <div align="center"><img srcset="img/cuda5.png 320w,
                    img/cuda5.png  480w,img/cuda5.png  800w"
                    sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
                    src="img/cuda5.png"  alt="Proceso" class="imagen">
                </div>
            <br>
            <h3>Librerías de programación paralela CUDA</h3>
                <p>
                    Las tres bibliotecas para algoritmos paralelos tienen diferentes propósitos. NCCL (Biblioteca de comunicaciones colectivas de Nvidia) es para escalar aplicaciones en múltiples GPU y nodos; nvGRAPH es para análisis de gráficos paralelos; y Thrust es una biblioteca de plantillas de C ++ para CUDA basada en la biblioteca de plantillas estándar de C ++. Thrust proporciona una rica colección de primitivas paralelas de datos como escanear, ordenar y reducir. </p>
                <div align="center"><img srcset="img/cuda6.png 320w,
                    img/cuda6.png 480w,img/cuda6.png 800w"
                    sizes="(max-width: 320px) 280px,(max-width: 480px) 440px,800px"
                    src="img/cuda6.png"  alt="Proceso" class="imagen">
                </div>
            <br>
            
        </section>
        
        <div class="container_busqueda">
           
            <div id="search-wrapper">
                <input type="search" id="search" placeholder="Buscar"/>
                <i class="fa fa-search"></i>
              </div>
            <ul id="resultado" class="lista_busqueda">
                
            </ul>
        </div>
        </div>
        
        </div>
    </main>
        
 
<footer>
    <div class="container-pie">
        <div class="copyright">
           <p>&copy; 2020 Página realizada por estudiantes de la Universidad UTE.</p> 
        </div>
    </div>
</footer>
</div>

<script src="js/jQuery.js"></script>
<script src="js/scripts.js"></script>
<script src="js/prism.js"></script>



<script>
    const temas = [  /*Cargar aqui enlaces para la busqueda con el mismo formato.*/
    {titulo: '<a href="Expresiones_Lambda.html">Expresiones Lambda</a>'},   
        {titulo: '<a href="Metodos_estaticos.html">Métodos Estáticos</a>'},   
        {titulo: '<a href="ForkJoin.html">ForkJoin</a>'}, 
        {titulo: '<a href="Hilo_Sincronizacion.html">Hilos y Sincronización</a>'},
        {titulo: '<a href="JavaStreams.html">Java Streams</a>'},    
        {titulo: '<a href="ip.html">TCP/IP, Sockets UDP</a>'}, 
        {titulo: '<a href="MapReduce.html">MapReduce</a>'}, 
        {titulo: '<a href="TCP.html">Sockets UTP</a>'}, 
        {titulo: '<a href="Contenedores.html">Contenedores</a>'}, 
		{titulo: '<a href="VirtualBox.html">VirtualBox</a>'}, 
        {titulo: '<a href="Docker.html">Docker</a>'}, 
        {titulo: '<a href="MaquinaVirtual.html">Máquina Virtual </a>'}, 
        {titulo: '<a href="InyeccionDependencia.html">Inyeccion de Dependencias </a>'}, 
        {titulo: '<a href="ConvencionSobreConfiguracion.html">Convención Sobre Configuración </a>'}, 
        {titulo: '<a href="FreeMarker.html">FreeMarker </a>'}, 
        {titulo: '<a href="SpringMVC.html">Creación de aplicaciones web con Spring MVC </a>'},
        {titulo: '<a href="Groovy.html">Groovy </a>'},
        {titulo: '<a href="Spring.html">Spring </a>'},
        {titulo: '<a href="Spring_Boot.html">Spring boot </a>'},
        {titulo: '<a href="Orm.html">ORM </a>'},
        {titulo: '<a href="JPA.html">JPA </a>'},  
        {titulo: '<a href="JSP.html">JSP </a>'},
        {titulo: '<a href="inversiondecontrol.html">Inversion de Control </a>'}, 
        {titulo: '<a href="ServicioWeb.html">Servicio Web </a>'},

        {titulo: '<a href="NFS.html">NFS</a>'},
        {titulo: '<a href="samba.html">Samba</a>'},
        {titulo: '<a href="GlusterFs.html">GlusterFs</a>'},
        {titulo: '<a href="HDFS.html">HDFS </a>'},
        {titulo: '<a href="Hadoop.html">Hadoop</a>'},
        {titulo: '<a href="Spark.html">Spark </a>'},
        {titulo: '<a href="Multiproceso.html">Multiproceso </a>'},
        {titulo: '<a href="mpi.html">Mpi</a>'},
        {titulo: '<a href="ZeroMQ.html">ZeroMQ </a>'},
        {titulo: '<a href="NNG.html">NNG </a>'},
        {titulo: '<a href="CUDA.html">cuda </a>'},
    ]
    const formulario= document.querySelector('#search');
    const boton= document.querySelector('#boton');
    const resultado=document.querySelector('#resultado');

    const filtrar = ()=>{
       resultado.innerHTML='';

       const texto = formulario.value.toLowerCase();
       for(let tema of temas ){
           let titulo=tema.titulo.toLowerCase();
           if(titulo.indexOf(texto) !== -1){
               
                resultado.innerHTML += '<li>'+tema.titulo+'</li>'
         }
        }
        if(resultado.innerHTML===''){
            resultado.innerHTML += '<li>Enlace no Encontrado...</li>'
        }
    }
    //boton.addEventListener('click',filtrar)
    formulario.addEventListener('keyup',filtrar);
   
    
</script>       
        
        
    
</body>
</html>
